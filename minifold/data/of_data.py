import json
import os
from typing import Optional, Any

import ml_collections as mlc
import pytorch_lightning as pl
import torch

from minifold.data import data_pipeline, feature_pipeline, mmcif_parsing


def get_data(file_id, path, mode, config, chain_id=None):
    d_pipeline = data_pipeline.DataPipeline(template_featurizer=None)
    f_pipeline = feature_pipeline.FeaturePipeline(config)

    with open(path, "r") as f:
        mmcif_string = f.read()

    mmcif_object = mmcif_parsing.parse(file_id=file_id, mmcif_string=mmcif_string)

    if mmcif_object.mmcif_object is None:
        raise list(mmcif_object.errors.values())[0]

    data = d_pipeline.process_mmcif(
        mmcif=mmcif_object.mmcif_object,
        alignment_dir=None,
        chain_id=chain_id,
        alignment_index=None,
        seqemb_mode=True,
    )

    feats = f_pipeline.process_features(data, mode)

    return feats


def of_inference(sequence, mode, config):
    f_pipeline = feature_pipeline.FeaturePipeline(config)
    seq_features = data_pipeline.make_sequence_features(
        sequence=sequence,
        description="",
        num_res=len(sequence),
    )
    msa_features = data_pipeline.make_dummy_msa_feats(sequence)
    data = {**seq_features, **msa_features}

    feats = f_pipeline.process_features(data, mode)
    return feats


class OpenFoldSingleDataset(torch.utils.data.Dataset):
    def __init__(
        self,
        data_dir: str,
        alignment_dir: str,
        template_mmcif_dir: str,
        max_template_date: str,
        config: mlc.ConfigDict,
        chain_data_cache_path: Optional[str] = None,
        kalign_binary_path: str = "/usr/bin/kalign",
        max_template_hits: int = 4,
        obsolete_pdbs_file_path: Optional[str] = None,
        template_release_dates_cache_path: Optional[str] = None,
        shuffle_top_k_prefiltered: Optional[int] = None,
        treat_pdb_as_distillation: bool = True,
        filter_path: Optional[str] = None,
        mode: str = "train",
        alignment_index: Optional[Any] = None,
        _output_raw: bool = False,
        _structure_index: Optional[Any] = None,
    ):
        """
        Args:
            data_dir:
                A path to a directory containing mmCIF files (in train
                mode) or FASTA files (in inference mode).
            alignment_dir:
                A path to a directory containing only data in the format
                output by an AlignmentRunner
                (defined in openfold.features.alignment_runner).
                I.e. a directory of directories named {PDB_ID}_{CHAIN_ID}
                or simply {PDB_ID}, each containing .a3m, .sto, and .hhr
                files.
            template_mmcif_dir:
                Path to a directory containing template mmCIF files.
            config:
                A dataset config object. See openfold.config
            chain_data_cache_path:
                Path to cache of data_dir generated by
                scripts/generate_chain_data_cache.py
            kalign_binary_path:
                Path to kalign binary.
            max_template_hits:
                An upper bound on how many templates are considered. During
                training, the templates ultimately used are subsampled
                from this total quantity.
            template_release_dates_cache_path:
                Path to the output of scripts/generate_mmcif_cache.
            obsolete_pdbs_file_path:
                Path to the file containing replacements for obsolete PDBs.
            shuffle_top_k_prefiltered:
                Whether to uniformly shuffle the top k template hits before
                parsing max_template_hits of them. Can be used to
                approximate DeepMind's training-time template subsampling
                scheme much more performantly.
            treat_pdb_as_distillation:
                Whether to assume that .pdb files in the data_dir are from
                the self-distillation set (and should be subjected to
                special distillation set preprocessing steps).
            mode:
                "train", "val", or "predict"
        """
        super(OpenFoldSingleDataset, self).__init__()

        self.data_dir = data_dir

        self.chain_data_cache = None
        if chain_data_cache_path is not None:
            with open(chain_data_cache_path, "r") as fp:
                self.chain_data_cache = json.load(fp)
            assert isinstance(self.chain_data_cache, dict)

        self.alignment_dir = alignment_dir
        self.config = config
        self.treat_pdb_as_distillation = treat_pdb_as_distillation
        self.mode = mode
        self.alignment_index = alignment_index
        self._output_raw = _output_raw
        self._structure_index = _structure_index

        self.supported_exts = [".cif", ".core", ".pdb"]
        template_featurizer = None

        self.data_pipeline = data_pipeline.DataPipeline(
            template_featurizer=template_featurizer,
        )

        if not self._output_raw:
            self.feature_pipeline = feature_pipeline.FeaturePipeline(config)

    def _parse_mmcif(self, path, file_id, chain_id, alignment_dir, alignment_index):
        with open(path, "r") as f:
            mmcif_string = f.read()

        mmcif_object = mmcif_parsing.parse(file_id=file_id, mmcif_string=mmcif_string)

        # Crash if an error is encountered. Any parsing errors should have
        # been dealt with at the alignment stage.
        if mmcif_object.mmcif_object is None:
            raise list(mmcif_object.errors.values())[0]

        mmcif_object = mmcif_object.mmcif_object

        data = self.data_pipeline.process_mmcif(
            mmcif=mmcif_object,
            alignment_dir=alignment_dir,
            chain_id=chain_id,
            alignment_index=alignment_index,
            seqemb_mode=True,
        )

        return data

    def chain_id_to_idx(self, chain_id):
        return self._chain_id_to_idx_dict[chain_id]

    def idx_to_chain_id(self, idx):
        return self._chain_ids[idx]

    def __getitem__(self, idx):
        if self.mode == "train" or self.mode == "eval":
            path = idx
            ext = ".cif"
            file_id = "AF-A0A2D6UT34-F1"
            chain_id = None
            alignment_dir = None
            alignment_index = None

            if ext == ".cif":
                data = self._parse_mmcif(
                    path,
                    file_id,
                    chain_id,
                    alignment_dir,
                    alignment_index,
                )
            elif ext == ".core":
                data = self.data_pipeline.process_core(
                    path,
                    alignment_dir,
                    alignment_index,
                    seqemb_mode=self.config.seqemb_mode.enabled,
                )
            elif ext == ".pdb":
                structure_index = None
                if self._structure_index is not None:
                    structure_index = self._structure_index[name]
                data = self.data_pipeline.process_pdb(
                    pdb_path=path,
                    alignment_dir=alignment_dir,
                    is_distillation=self.treat_pdb_as_distillation,
                    chain_id=chain_id,
                    alignment_index=alignment_index,
                    _structure_index=structure_index,
                    seqemb_mode=self.config.seqemb_mode.enabled,
                )
            else:
                raise ValueError("Extension branch missing")
        else:
            path = os.path.join(name, name + ".fasta")
            data = self.data_pipeline.process_fasta(
                fasta_path=path,
                alignment_dir=alignment_dir,
                alignment_index=alignment_index,
                seqemb_mode=self.config.seqemb_mode.enabled,
            )

        if self._output_raw:
            return data

        feats = self.feature_pipeline.process_features(data, self.mode)
        return feats

    def __len__(self):
        return len(self._chain_ids)
